{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install ipywidgets\n",
    "!pip install accelerate\n",
    "!pip install transformers\n",
    "!pip install langchain\n",
    "# !pip install chromadb\n",
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-3b\", padding_side=\"left\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"databricks/dolly-v2-3b\", device_map=\"auto\")\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024,\n",
    "    temperature=0.8,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offloaded_weights\"\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt_template)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"product\"],\n",
    "#     template=\"What is a good name for a company that makes {product}?\",\n",
    "# )\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Write a catchphrase for the following company: {company_name}\",\n",
    ")\n",
    "\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "catchphrase = overall_chain.run(\"colorful socks\")\n",
    "print(catchphrase)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
